import time
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, Dataloader
from tqdm import tqdm

from transformers import BertTokenizerFast
from mlm_pytorch import MLM

from process_dataset import read_format, DocumentList
from nearest_neighbor import knn


class DocumentDataset(Dataset):
    def __init__(self, path):
        """ Let N be number of documents and d embedding dimension:

            self.documents: DocumentList of N
            self.embeddings: N x d array
        """
        documents, embeddings = [], []
        for chunk in glob.glob(f'{path}/*'):
            # Only read name from one file
            if chunk.endswith('.npy'):
                continue
            name = t.rstrip('_doc.pl')
            _, chunk_documents, chunk_embeddings = read_format(name)
            documents.append(chunk_documents)
            embeddings.append(chunk_embeddings)

        self.documents = DocumentList(documents)
        self.embeddings = np.concatenate(embeddings)

    def __len__(self):
        return len(self.documents)

    def __getitem__(self, idx):
        return self.documents[idx], self.embeddings[idx]


latent_dataset = DocumentDataset('cc_news_smaller_processed_split/latent')


tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')
tokenizer.max_len = 1024


def tokenize(text):
    tokenized = tokenizer.encode(text,
                                 max_length=tokenizer.max_len,
                                 add_special_tokens=True,
                                 truncation=True)
    tokenized = torch.tensor(tokenized, dtype=torch.long)
    num_pad = tokenizer.max_len - tokenized.shape[0]
    tokenized = torch.concat((tokenized, torch.zeros(num_pad, dtype=torch.long)))
    return tokenized


def join(text1, text2):
    return text1 + ' [SEP] ' + text2


class TaskDataset(Dataset):
    def __init__(self, path, latent=None):
        """ Let N be number of documents and k how many latent documents

            self.dataset: task dataset
            self.latent: type of latent document search
            self.references: N x k array of k document indicies
        """
        dataset = DocumentDataset(path)

        self.latent = latent
        if latent = 'nn':
            self.references = knn(dataset.embeddings, latent_dataset.embeddings)
        elif latent == 'scatter-gather':
            self.references = None

        tokenized, self.stop_indicies = [], []
        for i, document in enumerate(dataset):
            text = document['text']
            # Please fix inefficiency here lel
            tokenized = tokenizer.encode(text,
                                         max_length=tokenizer.max_len,
                                         add_special_tokens=True,
                                         truncation=True)
            if self.latent:
                stop_indicies.append(tokenized.shape[0])
                # Take first document due to time limit
                reference_index = self.references[i][0]
                text = join(text, latent_dataset.documents[reference_index])
            tokenized.append(tokenize(text))
        self.tokenized = torch.tensor(tokenized)


    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        if self.latent:
            return self.tokenized[idx], self.stop_indicies[idx]
        return self.tokenized[idx], None


def load_batch(batch):
    """ Processs batch generated by dataloader of task dataset for model usage """
    tokenized, stop_index = batch
    if torch.cuda.is_available():
        tokenized = tokenized.cuda()
        if latent:
            stop_index = stop_index.cuda()
    return tokenized, stop_index


def run_experiment(name, latent=None, epochs=200, plot=True):
    """ Run train experiment given latent database structure

        plot visualizes the train and val losses
    """
    task_dataset = TaskDataset(
        'cc_news_smaller_processed_split/train', latent=latent)
    train_dataset, validation_dataset = \
        torch.utils.data.random_split(
            task_dataset, [9000, len(task_dataset) - 9000])

    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    validation_loader = DataLoader(validation_dataset, batch_size=16, shuffle=True)

    trainer = MLM(transformer,
                  mask_token_id=103,
                  pad_token_id=0,
                  mask_prob=0.15,
                  replace_prob=0.90,
                  mask_ignore_token_ids = [101, 102])

    if torch.cuda.is_available():
        trainer = trainer.cuda()

    optimizer = torch.optim.Adam(trainer.parameters(), lr=3e-4)

    train_losses, validation_losses = [], []

    for epoch in tqdm(range(epochs)):
        print(f'Epoch-{epoch}')

        train_loss, validation_loss = 0, 0

        transformer.train()
        for i, batch in enumerate(train_loader):
            tokenized, stop_index = load_batch(batch)
            optimizer.zero_grad()
            loss = trainer(tokenized, stop_index)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()

        transformer.eval()
        for i, batch in enumerate(validation_loader):
            tokenized, stop_index = load_batch(batch)
            loss = trainer(tokenized, stop_index)
            validation_loss += loss.item()

        train_losses.append(train_loss)
        validation_losses.append(validation_loss)

    print(train_losses)
    print(validation_losses)

    if plot:
        plt.plot(train_losses)
        plt.plot(val_losses)
        plt.savefig(f'{name}_losses.png')


def main():
    run_experiment('no_latent')


if __name__ == '__main__':
    main()
